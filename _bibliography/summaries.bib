---
---

@article{1802.05365v2,
  author        = {Matthew E. Peters and Mark Neumann and Mohit Iyyer and Matt Gardner and Christopher Clark and Kenton Lee and Luke Zettlemoyer},
  title         = {Deep contextualized word representations},
  eprint        = {1802.05365v2},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  abstract      = {We introduce a new type of deep contextualized word representation that
                   models both (1) complex characteristics of word use (e.g., syntax and
                   semantics), and (2) how these uses vary across linguistic contexts (i.e., to
                   model polysemy). Our word vectors are learned functions of the internal states
                   of a deep bidirectional language model (biLM), which is pre-trained on a large
                   text corpus. We show that these representations can be easily added to existing
                   models and significantly improve the state of the art across six challenging
                   NLP problems, including question answering, textual entailment and sentiment
                   analysis. We also present an analysis showing that exposing the deep internals
                   of the pre-trained network is crucial, allowing downstream models to mix
                   different types of semi-supervision signals.},
  year          = {2018},
  month         = {Feb},
  url           = {http://arxiv.org/abs/1802.05365v2},
  file          = {1802.05365v2.pdf},
  eprintnover   = {1802.05365}
}

@article{2103.11251v2,
  author        = {Chudi Zhong and Cynthia Rudin and Chaofen Chen and Zhi Chen and Haiyang Huang and Lesia Semenova},
  title         = {Interpretable Machine Learning: Fundamental Principles and 10 Grand Challenges},
  eprint        = {2103.11251v2},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  abstract      = {Interpretability in machine learning (ML) is crucial for high stakes decisions and troubleshooting. In this work, we provide fundamental principles for interpretable ML, and dispel 
                    common misunderstandings that dilute the importance of this crucial topic. We also identify
                    10 technical challenge areas in interpretable machine learning and provide history and background on each problem. Some of these problems are classically important, and some are
                    recent problems that have arisen in the last few years. These problems are: (1) Optimizing
                    sparse logical models such as decision trees; (2) Optimization of scoring systems; (3) Placing
                    constraints into generalized additive models to encourage sparsity and better interpretability;
                    (4) Modern case-based reasoning, including neural networks and matching for causal inference; (5) Complete supervised disentanglement of neural networks; (6) Complete or even partial unsupervised disentanglement of neural networks; (7) Dimensionality reduction for data
                    visualization; (8) Machine learning models that can incorporate physics and other generative
                    or causal constraints; (9) Characterization of the “Rashomon set” of good models; and (10)
                    Interpretable reinforcement learning. This survey is suitable as a starting point for statisticians
                    and computer scientists interested in working in interpretable machine learning},
  year          = {2021},
  month         = {July},
  url           = {https://arxiv.org/abs/2103.11251v2},
  file          = {2103.11251v2.pdf},
  eprintnover   = {2103.11251}
}

@article{2209.08040v2,
  author        = {Rui Xin and Chudi Zhong and Zhi Chen and Takuya Takagi and Margo Seltzer and Cynthia Rudin},
  title         = {Exploring the Whole Rashomon Set of Sparse Decision Trees},
  eprint        = {2209.08040v2},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  abstract      = {In any given machine learning problem, there might be many models that explain
                    the data almost equally well. However, most learning algorithms return only one
                    of these models, leaving practitioners with no practical way to explore alternative
                    models that might have desirable properties beyond what could be expressed by
                    a loss function. The Rashomon set is the set of these all almost-optimal models.
                    Rashomon sets can be large in size and complicated in structure, particularly
                    for highly nonlinear function classes that allow complex interaction terms, such
                    as decision trees. We provide the first technique for completely enumerating the
                    Rashomon set for sparse decision trees; in fact, our work provides the first complete
                    enumeration of any Rashomon set for a non-trivial problem with a highly nonlinear
                    discrete function class. This allows the user an unprecedented level of control over
                    model choice among all models that are approximately equally good. We represent
                    the Rashomon set in a specialized data structure that supports efficient querying
                    and sampling. We show three applications of the Rashomon set: 1) it can be used to
                    study variable importance for the set of almost-optimal trees (as opposed to a single
                    tree), 2) the Rashomon set for accuracy enables enumeration of the Rashomon sets
                    for balanced accuracy and F1-score, and 3) the Rashomon set for a full dataset
                    can be used to produce Rashomon sets constructed with only subsets of the data
                    set. Thus, we are able to examine Rashomon sets across problems with a new lens,
                    enabling users to choose models rather than be at the mercy of an algorithm that
                    produces only a single model.},
  year          = {2022},
  month         = {Oct},
  url           = {https://arxiv.org/abs/2209.08040},
  file          = {2209.08040.pdf},
  eprintnover   = {2209.08040}
}